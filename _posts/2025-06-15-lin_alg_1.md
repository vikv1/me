---
layout: post
title: Self Studying Linear Algebra
categories:
- Academics
feature_text: |
  matrices and whatnot
blurb: mit 18.06 thoughts #1
date: 2025-07-15
---

The professor is a very engaging lecturer, although the lectures I feel are relatively short. I'm already starting to see and think about how this can applied to performing large calculations, although I'd like to look more into how these calculations can be done faster. Currently we can define an upper bound of O(n<sup>3</sup>) for matrix multiplication because we have to perform n<sup>2</sup> calculations for each row in the matrix. There are some faster algorithms like Strassen's and Coppersmith-Winograd's which reduce the overall time complexity to just under n<sup>3</sup>. 

A cool improvement although the drawback of analyzing algorithms solely by their asymptotic upper bound is that we ignore constant factors which (unfortunately) do affect our real execution speed. I'd like to look more into this though!